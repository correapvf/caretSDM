% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/evaluate.R
\name{evaluate.train}
\alias{evaluate.train}
\alias{plot.evaluate.train}
\alias{dotplot.evaluate.train}
\alias{pairs.evaluate.train}
\title{Evaluate a caret model}
\usage{
\method{evaluate}{train}(
  x,
  testdata = NULL,
  testy = NULL,
  testindex = NULL,
  summaryFunction = NULL,
  calc.train = TRUE,
  errorFunction = ci_95,
  ...
)

\method{plot}{evaluate.train}(x, plot_errorbar = TRUE, ...)

\method{dotplot}{evaluate.train}(x, data = NULL, metric = "all", ...)

\method{pairs}{evaluate.train}(x, data = NULL, metric = NULL, fixed_axis = TRUE, ...)
}
\arguments{
\item{x}{An object returned by \code{evaluate}.}

\item{testdata}{A data.frame with test values to be evaluated. If \code{NULL}, training values will be used.}

\item{testy}{A factor of response variable of \code{testdata}. If \code{NULL}, it will be guessed from \code{testdata} data.frame.}

\item{testindex}{A list with rows index of testdata for each resample, preferably an output of
\code{\link{create.test.index}} or \code{\link{create.test.index.blockCV}}. If \code{NULL}, indexes are create based on 
the same methods provided by \code{trainControl} used in the model. Only used if \code{error_bar = TRUE}.}

\item{summaryFunction}{A Summary function (one of \code{\link[caret]{defaultSummary}}) that calculate the metrics. 
If \code{NULL}, the summaryFunction provided in the model will be used.}

\item{calc.train}{logical. Evaluate training data? If \code{FALSE}, only test data is evaluated.}

\item{errorFunction}{A function used to calculate errors across resamples. Default is 95\% confidence interval.
If \code{NULL}, errors are not calculated.}

\item{...}{ignored}

\item{plot_errorbar}{logical. Should plot error bars?}

\item{data}{Which data type to plot? Should be either 'train' or 'test'.
When \code{NULL}, it defaults to test data, if present.}

\item{metric}{A character, indicating which metric to plot. If \code{NULL},
only the first metric is plotted. If 'all', all metrics are plotted.}

\item{fixed_axis}{logical. Should axis in all plots be fixed to the same limits?}
}
\value{
An S3 object of class 'evaluate.train', including:
\itemize{
  \item eval - A data.table in the long format with data type, metrics, values and error across resamples.
  If \code{errorFunction != NULL}, values are means across resamples.
  \item resample - A data.table with metrics in each resample.
  }
}
\description{
Evaluate a caret model using the metrics of \code{summaryFunction}.
}
\note{
This function is somewhat similar to \code{\link[caret]{resamples}}, however this function 
supports evaluation using test data, a custom threshold (use \code{setThreshold}), or a different summaryFunction.
}
\examples{
\dontrun{
evaluate(model)

# evaluate test data only
testindex <- create.test.index(testdata$response) # get response of testdata
evaluate(model, testdata, testindex = testindex, calc.train = FALSE)

# for multiple models
models <- list(model1, model2, model3)
e <- evaluate(models, summaryFunction = twoClassSummary)
plot(e)
dotplot(e, data.type = "test", metric = "ROC")
pairs(e)
pairs(e, fixed_axis = FALSE)
}
}
\seealso{
\code{\link{confusionMatrix2}} \code{\link{ROCcurve}}
}
